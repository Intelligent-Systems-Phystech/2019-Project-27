{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRanks(trecks):\n",
    "    filename = 'Data/ranks' + str(trecks) + '.txt'\n",
    "    return pd.read_csv(filename, delimiter=' ', names=['QueryId', 'smth', 'document', 'tag'])\n",
    "\n",
    "def loadMetadata(filename):\n",
    "    lines = map(lambda x: x.strip().split(' '), open(filename, 'r').readlines())\n",
    "    return dict(map(lambda x: (x[0], float(x[1])), lines))\n",
    "\n",
    "def isMember(arr, to_remain):\n",
    "    result, indexes = [], []\n",
    "    for i, elem in enumerate(arr):\n",
    "        result.append(elem in to_remain)\n",
    "        if result[-1]:\n",
    "            indexes.append(np.where(to_remain == elem)[0][0])\n",
    "            \n",
    "    return np.array(result), np.array(indexes)\n",
    "\n",
    "def loadCode(ranks, qId, qIndex, trecks):\n",
    "    metadata = loadMetadata('Data/Data/metadata' + str(trecks) + '.txt')\n",
    "    \n",
    "    doc_id_string = pd.read_csv('Data/Data{0}/doc_id_strings{1}.txt'.format(trecks, qIndex),\n",
    "                               delimiter=' ',\n",
    "                               names=['Name', 'Id'])\n",
    "    \n",
    "    term_doc_vars = pd.read_csv('Data/Data{0}/termvars{1}.txt'.format(trecks, qIndex),\n",
    "                               delimiter=' ',\n",
    "                               names=['Q1', 'Q2', 'Q3'])\n",
    "    \n",
    "    lengthForTerms = np.array(list(map(lambda x: int(x.strip()),\n",
    "                         open('Data/Data{0}/lengthForTerms{1}.txt'.format(trecks, qIndex), 'r').readlines())))\n",
    "    \n",
    "    q_ranks = ranks[ranks['QueryId'] == qId]\n",
    "    docs_to_retrive = q_ranks['document'].values \n",
    "    \n",
    "    inds_to_retrive, _ = isMember(doc_id_string['Name'].values, docs_to_retrive)\n",
    "    \n",
    "    doc_id_retrive = doc_id_string[inds_to_retrive]\n",
    "    ids_to_retrive = doc_id_retrive['Id'].values\n",
    "    \n",
    "    start = 0\n",
    "    vecDelimCopy = np.ones(lengthForTerms.shape)\n",
    "    matTermDocVarsCopy = None\n",
    "\n",
    "    for i in np.arange(lengthForTerms.shape[0]):\n",
    "        \n",
    "        slice_to_work_with = term_doc_vars[start:start+lengthForTerms[i]]\n",
    "        vec_from_slice = slice_to_work_with[slice_to_work_with.columns[0]].values\n",
    "        \n",
    "        inds_to_remain, _ = isMember(vec_from_slice, ids_to_retrive)\n",
    "        slice_to_work_with = slice_to_work_with.iloc[inds_to_remain]\n",
    "        \n",
    "        if matTermDocVarsCopy is None:\n",
    "            matTermDocVarsCopy = slice_to_work_with\n",
    "        else:\n",
    "            matTermDocVarsCopy = pd.concat([matTermDocVarsCopy, slice_to_work_with])\n",
    "        vecDelimCopy[i] = len(inds_to_remain)        \n",
    "        start += lengthForTerms[i]\n",
    "    \n",
    "    matTermDocVars = matTermDocVarsCopy\n",
    "    vecDelim = vecDelimCopy.T\n",
    "\n",
    "    return (metadata, doc_id_retrive, q_ranks, matTermDocVars, vecDelim)\n",
    "    \n",
    "def rewriteRanks(vecNamesDocRanks, matDocIdStr):\n",
    "    vecNamesIdStr = matDocIdStr.iloc[:, 0].values\n",
    "    vecIdsIdStr = matDocIdStr.iloc[:, 1].values\n",
    "    \n",
    "    _, indInNamesIdStr = isMember(vecNamesDocRanks, vecNamesIdStr)\n",
    "\n",
    "    idsOfDocRanks = vecIdsIdStr[indInNamesIdStr]\n",
    "\n",
    "    return np.sort(idsOfDocRanks)\n",
    "\n",
    "def loadData(trecks):\n",
    "    ranks = loadRanks(trecks)\n",
    "    \n",
    "    queries = pd.read_csv('Data/Data/queries' + str(trecks) + '.txt', \n",
    "                          delimiter='#',\n",
    "                          names=['Id', 'Query'])\n",
    "\n",
    "    modelCharacteristics = [None for i in range(queries.values.shape[0])]\n",
    "    mat_doc_ranks = [[None, None, None, None, None] for i in range(queries.values.shape[0])]\n",
    "\n",
    "    for i, query_id in enumerate(queries['Id'].values):\n",
    "\n",
    "        print(\"Query : \", query_id)\n",
    "\n",
    "        matMetaData, matDocIdStr, matDocRanks, matTermDocVars, vecDelim = loadCode(ranks, query_id, i + 1, trecks)\n",
    "        \n",
    "        AvDocLen = matMetaData['AverageDocumentLength']\n",
    "        NumbDocs = matMetaData['NumberOfDocuments']\n",
    "\n",
    "        ulabel, uindex = np.unique(matTermDocVars[matTermDocVars.columns[0]], return_inverse=True)\n",
    "        modelCharacteristics[i] = [ulabel, uindex]\n",
    "        \n",
    "        xvars = matTermDocVars.iloc[:,1].values * np.log10((AvDocLen + matTermDocVars.iloc[:, 2].values) / \n",
    "                                                           matTermDocVars.iloc[:, 2].values)\n",
    "        yvars = vecDelim / NumbDocs\n",
    "        \n",
    "        yvarsExt_ed = np.repeat(yvars, vecDelim.astype(np.int32))\n",
    "        modelCharacteristics[i].append([xvars, yvarsExt_ed])\n",
    "        \n",
    "        for j in range(4):\n",
    "            mat_doc_ranks[i][j] = matDocRanks.iloc[:, j]\n",
    "        \n",
    "        vecDocNamesEv  = matDocRanks.iloc[:, 2].values\n",
    "        vecDocRanksEv  = matDocRanks.iloc[:, 3].values\n",
    "        mat_doc_ranks[i][2]  = vecDocNamesEv[vecDocRanksEv == 1]\n",
    "        mat_doc_ranks[i][4] = rewriteRanks(mat_doc_ranks[i][2], matDocIdStr)\n",
    "    stop = True\n",
    "    return (mat_doc_ranks, queries, modelCharacteristics, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'Data/Data/queries6.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a82a84422e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_ranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_characteristics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-d9a15e82b007>\u001b[0m in \u001b[0;36mloadData\u001b[0;34m(trecks)\u001b[0m\n\u001b[1;32m     77\u001b[0m     queries = pd.read_csv('Data/Data/queries' + str(trecks) + '.txt', \n\u001b[1;32m     78\u001b[0m                           \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                           names=['Id', 'Query'])\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mmodelCharacteristics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'Data/Data/queries6.txt' does not exist"
     ]
    }
   ],
   "source": [
    "doc_ranks, queries, query_characteristics = loadData(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "\n",
    "class Domain:\n",
    "    def __init__(self, low, high):\n",
    "        self.low = min(low, high)\n",
    "        self.high = max(low, high)\n",
    "    \n",
    "    def contain(self, nDomain):\n",
    "        return self.low <= nDomain.low and nDomain.high <= self.high\n",
    "\n",
    "class DOMAINS:\n",
    "    REAL = Domain(-np.inf, np.inf)\n",
    "    POSITIVE = Domain(0, np.inf)\n",
    "    NEGATIVE = Domain(-np.inf, 0)\n",
    "    TWICE_REAL = (REAL, REAL)\n",
    "\n",
    "\n",
    "class DomainException(Exception):\n",
    "    pass\n",
    "\n",
    "class Primitive:\n",
    "\n",
    "    def __init__(self, func, valency, domain, codomain, string):\n",
    "        self.func = func\n",
    "        self.valency = valency\n",
    "        self.nodes = []\n",
    "        self.domain = domain\n",
    "        self.codomain = codomain\n",
    "        self.str = string\n",
    "\n",
    "    def add_nodes(self, nodes):\n",
    "        self.nodes = nodes\n",
    "        return self\n",
    "\n",
    "    def calc(self, x, y):\n",
    "        if self.valency == 0:\n",
    "            return self.func(x, y)\n",
    "        return self.func(*[node.calc(x, y) for node in self.nodes])\n",
    "\n",
    "    def calc_domains(self):\n",
    "        nodes_domains = [node.calc_domains() for node in self.nodes]\n",
    "\n",
    "        if self.valency == 0:\n",
    "            pass\n",
    "        elif self.valency == 1:\n",
    "            if not self.domain.contain(nodes_domains[0]):\n",
    "                raise DomainException()\n",
    "            self.domain = nodes_domains[0]\n",
    "            self.codomain = Domain(self.func(self.domain.low), self.func(self.domain.high))\n",
    "\n",
    "        elif self.valency == 2:\n",
    "            \n",
    "            # TODO избавиться от switch\n",
    "            fr, sc = nodes_domains\n",
    "\n",
    "            if self.func == np.add:\n",
    "                self.codomain = Domain(fr.low + sc.low, fr.high + sc.high)\n",
    "            elif self.func == np.subtract:\n",
    "                self.codomain = Domain(fr.low - sc.high, fr.high - sc.low)\n",
    "            elif self.func == np.multiply:\n",
    "                vars = np.array([fr.low * sc.low, fr.low * sc.high, fr.high * sc.low, fr.high * sc.high])\n",
    "                vars = vars[vars == vars] # TODO bug\n",
    "                self.codomain = Domain(np.min(vars), np.max(vars))\n",
    "\n",
    "            elif self.func == np.divide:\n",
    "                \n",
    "                # TODO сделать честное вычисление\n",
    "\n",
    "                vars = np.array([fr.low * sc.low, fr.low * sc.high, fr.high * sc.low, fr.high * sc.high])\n",
    "                vars = vars[vars == vars] # TODO bug\n",
    "                tmin, tmax = np.min(vars), np.max(vars)\n",
    "                if tmin < 0 and tmax > 0:\n",
    "                    self.codomain = DOMAINS.REAL\n",
    "                elif tmax <= 0:\n",
    "                    self.codomain = DOMAINS.NEGATIVE\n",
    "                elif tmin >= 0:\n",
    "                    self.codomain = DOMAINS.POSITIVE\n",
    "                else:\n",
    "                    raise Exception('Comparison failed')\n",
    "            else:\n",
    "                raise Exception('Undefined function')\n",
    "        else:\n",
    "            raise Exception('Undefined valency')\n",
    "\n",
    "        return self.codomain\n",
    "\n",
    "    def get_tokens(self):\n",
    "        if self.valency == 0:\n",
    "            return 1\n",
    "        return 1 + np.sum([node.get_tokens() for node in self.nodes])\n",
    "    \n",
    "    def get_kth(self, n):\n",
    "        i = 0\n",
    "        while self.nodes[i].get_tokens() <= n:\n",
    "            n -= self.nodes[i].get_tokens()\n",
    "            i += 1\n",
    "        if n == 0:\n",
    "            return self, i\n",
    "        return self.nodes[i].get_kth(n - 1)\n",
    "        \n",
    "    def get_random(self):\n",
    "        rnd = np.random.randint(0, self.get_tokens() - 1)\n",
    "        return self.get_kth(rnd)\n",
    "    \n",
    "    def __str__(self):\n",
    "        nodes_names = [str(node) for node in self.nodes]\n",
    "        if self.valency == 0:\n",
    "            return self.str\n",
    "        elif self.valency == 1:\n",
    "            return self.str + '(' + nodes_names[0] + ')'\n",
    "        elif self.valency == 2:\n",
    "            return self.str + '(' + nodes_names[0] + ', ' + nodes_names[1] + ')'\n",
    "\n",
    "class Primitives:\n",
    "    TF = Primitive(lambda x, y: x, 0, DOMAINS.POSITIVE, DOMAINS.POSITIVE, 'tf')\n",
    "    IDF = Primitive(lambda x, y: y, 0, DOMAINS.POSITIVE, DOMAINS.POSITIVE, 'idf')\n",
    "    ADD = Primitive(np.add, 2, DOMAINS.TWICE_REAL, DOMAINS.TWICE_REAL, 'add')\n",
    "    SUB = Primitive(np.subtract, 2, DOMAINS.TWICE_REAL, DOMAINS.TWICE_REAL, 'substract')\n",
    "    MUL = Primitive(np.multiply, 2, DOMAINS.TWICE_REAL, DOMAINS.TWICE_REAL, 'multiply')\n",
    "    DIV = Primitive(np.divide, 2, DOMAINS.TWICE_REAL, DOMAINS.TWICE_REAL, 'divide')\n",
    "    LOG = Primitive(np.log, 1, DOMAINS.POSITIVE, DOMAINS.REAL, 'log')\n",
    "    EXP = Primitive(np.exp, 1, DOMAINS.REAL, DOMAINS.POSITIVE, 'exp')\n",
    "    SQRT = Primitive(np.sqrt, 1, DOMAINS.POSITIVE, DOMAINS.POSITIVE, 'sqrt')\n",
    "    \n",
    "PRIMITIVES = [ \n",
    "    Primitives.TF,\n",
    "    Primitives.IDF,\n",
    "    Primitives.ADD,\n",
    "    Primitives.SUB,\n",
    "    Primitives.MUL,\n",
    "    Primitives.DIV,\n",
    "    Primitives.LOG,\n",
    "    Primitives.EXP,\n",
    "    Primitives.SQRT,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def create_random_model(depth):\n",
    "    depth -= np.random.randint(0, 2) # construct not uniform binary trees\n",
    "\n",
    "    if depth <= 0:\n",
    "        return deepcopy(PRIMITIVES[np.random.randint(0, 2)]) # select randomly TF or IDF\n",
    "    else:\n",
    "        cur_primitive = deepcopy(PRIMITIVES[np.random.randint(0, len(PRIMITIVES))])\n",
    "        nodes = [create_random_model(depth - 1) for _ in range(cur_primitive.valency)]\n",
    "        cur_primitive.add_nodes(nodes)\n",
    "        return cur_primitive\n",
    "\n",
    "\n",
    "def create_population(size, max_depth):\n",
    "    population = []\n",
    "    for _ in range(size):\n",
    "        model = create_random_model(max_depth)\n",
    "        try:\n",
    "            model.calc_domains()\n",
    "            population.append(model)\n",
    "        except DomainException as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, query_characteristics):\n",
    "    values = model.calc(*query_characteristics[2])\n",
    "    result = np.zeros(query_characteristics[0].shape[0])\n",
    "    for i, pos in enumerate(query_characteristics[1]):\n",
    "        result[pos] += values[i]\n",
    "\n",
    "    return [query_characteristics[0], result]\n",
    "\n",
    "def evaluate_quality(query_id, doc_related, doc_ranks):\n",
    "    \n",
    "    vecDocIdEv = doc_ranks[4]\n",
    "    indsWhichAppear, _ = isMember(doc_related[0], vecDocIdEv)\n",
    "    doc_related.append(indsWhichAppear)\n",
    "\n",
    "    sort_indexes = np.argsort(doc_related[1])[::-1]\n",
    "\n",
    "    doc_related = np.array(doc_related)\n",
    "    doc_related = doc_related[:, sort_indexes]\n",
    "\n",
    "    ranksForRetrievedDocs = doc_related[2]\n",
    "    cumRanksForRetrievedDocs = np.cumsum(ranksForRetrievedDocs)\n",
    "    cutOffPrecision = cumRanksForRetrievedDocs / np.arange(1, ranksForRetrievedDocs.shape[0] + 1)\n",
    "    qualValue = np.sum(cutOffPrecision * ranksForRetrievedDocs) / doc_ranks[2].shape[0]\n",
    "    \n",
    "    return qualValue\n",
    "\n",
    "def get_quality(model, doc_ranks, queries, query_characteristics):\n",
    "\n",
    "    vec_quality = []\n",
    "    for i, query_id in enumerate(queries['Id'].values):\n",
    "        doc_related = evaluate_model(model, query_characteristics[i])\n",
    "        quality = evaluate_quality(query_id, doc_related, doc_ranks[i])\n",
    "        vec_quality.append(quality)\n",
    "    quality = np.sum(vec_quality)\n",
    "\n",
    "    # TODO add regularization \n",
    "    return quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_population(population, doc_ranks, queries, model_charactericts):   \n",
    "\n",
    "    qualities = []\n",
    "    for model in population:\n",
    "        quality = get_quality(model, doc_ranks, queries, model_charactericts)\n",
    "        if quality != quality or abs(quality) == np.inf:\n",
    "            quality = 0\n",
    "            \n",
    "        qualities.append(quality)\n",
    "\n",
    "    return qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:50: RuntimeWarning: divide by zero encountered in log\n",
      "/home/mike/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/mike/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "population = create_population(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_ranks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4dc32166ce04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_ranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_characteristics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_ranks' is not defined"
     ]
    }
   ],
   "source": [
    "learn_population(population, doc_ranks, queries, query_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_rand_tree(x):\n",
    "    if x.get_tokens() <= 2:\n",
    "        return x\n",
    "    x_ = deepcopy(x)\n",
    "    n1, id1 = x_.get_random()\n",
    "    n1.nodes[id1] = create_random_model(3)\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossfit(x, y):\n",
    "    if x.get_tokens() <= 2 or y.get_tokens() <= 2:\n",
    "        return x\n",
    "    x_ = deepcopy(x)\n",
    "    y_ = deepcopy(y)\n",
    "    n1, id1 = x_.get_random()\n",
    "    n2, id2 = y_.get_random()\n",
    "    n1.nodes[id1], n2.nodes[id2] = n2.nodes[id2], n1.nodes[id1]\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in exp\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in double_scalars\n",
      "  \n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in sqrt\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.97688689023271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.643119583882207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.699753885846793\n",
      "13.699753885846793\n",
      "13.699753885846793\n",
      "13.699753885846793\n",
      "13.699753885846793\n",
      "13.699753885846793\n",
      "13.699753885846793\n",
      "13.700005043200493\n",
      "13.700247822367583\n",
      "13.700247822367583\n",
      "13.700941903499787\n",
      "13.700941903499787\n",
      "13.700941903499787\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n",
      "13.80013948679012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d3a580a065ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnew_population\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_ranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_characteristics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-62d29ba3122b>\u001b[0m in \u001b[0;36mlearn_population\u001b[0;34m(population, doc_ranks, queries, model_charactericts)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mqualities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mquality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_ranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_charactericts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquality\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mquality\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mquality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c4ad90bc40fb>\u001b[0m in \u001b[0;36mget_quality\u001b[0;34m(model, doc_ranks, queries, query_characteristics)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdoc_related\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_characteristics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mquality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_related\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mvec_quality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c4ad90bc40fb>\u001b[0m in \u001b[0;36mevaluate_quality\u001b[0;34m(query_id, doc_related, doc_ranks)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvecDocIdEv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mindsWhichAppear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misMember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_related\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvecDocIdEv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdoc_related\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindsWhichAppear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d9a15e82b007>\u001b[0m in \u001b[0;36misMember\u001b[0;34m(arr, to_remain)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_remain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_remain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reit_ = 1e9\n",
    "last_reit = 1e9\n",
    "SIMILARITY = 1e-5\n",
    "\n",
    "for iteration in range(1000):\n",
    "    new_population = []\n",
    "    \n",
    "    sz = len(population)\n",
    "    \n",
    "    new_population.append(population[0])\n",
    "    \n",
    "    for i in range(sz // 30):\n",
    "        new_population.append(mutate_rand_tree(population[0]))\n",
    "        new_population.append(mutate_rand_tree(population[1]))\n",
    "        new_population.append(mutate_rand_tree(population[2]))\n",
    "    for i in range(sz // 10):\n",
    "        new_population.append(create_random_model(4))\n",
    "    for i in range(sz):\n",
    "        t1 = population[np.random.randint(0, sz / 2)]\n",
    "        t2 = population[np.random.randint(0, sz / 2)]\n",
    "        new_population.append(mutate_rand_tree(crossfit(t1, t2)))\n",
    "    \n",
    "    population = np.array(population + new_population)\n",
    "    values = learn_population(population, doc_ranks, queries, query_characteristics)\n",
    "    values = -np.array(values)\n",
    "    \n",
    "    indexes = np.arange(len(population))\n",
    "    indexes = sorted(indexes, key=lambda i: values[i])\n",
    "    \n",
    "    population = population[indexes]\n",
    "    values = values[indexes]\n",
    "    \n",
    "    ids = []\n",
    "    for i in range(20):\n",
    "        for q in range(i + 1, 20):\n",
    "            if values[i] - values[q] < SIMILARITY:\n",
    "                ids.append(q)\n",
    "                \n",
    "    ids = np.unique(ids)\n",
    "    population = [population[i] for i in range(100 + len(ids)) if i not in ids]\n",
    "    \n",
    "    print(-values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exp(divide(tf, exp(sqrt(tf))))'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(population[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exp(idf)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(population[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.80013948679012]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_population([population[0]], doc_ranks, queries, query_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in exp\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in log\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13.80013948679012,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 13.80013948679012,\n",
       " 7.67441302910452,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 8.23047524501977,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 9.86680437753825,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 7.702463983467008,\n",
       " 11.279487197554598,\n",
       " 7.013239174492782,\n",
       " 7.949633246290113,\n",
       " 11.865770175280934,\n",
       " 8.762713207595448,\n",
       " 5.6817778492139315,\n",
       " 6.564611072776034,\n",
       " 8.8670239512853,\n",
       " 5.567432812542736,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 6.801761184291343,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 8.23047524501977,\n",
       " 7.008858328856014,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 9.950859754157763,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.279700404712193,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 9.701692132094797,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 9.820961577051747,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 9.91998979333377,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 8.089629757565207,\n",
       " 11.67598795595149,\n",
       " 12.283619992408829,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 8.152746460672956,\n",
       " 7.5039211857352255,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 11.67598795595149,\n",
       " 6.566825588207697]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_population(population, doc_ranks, queries, query_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqrt(sqrt(exp(tf)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.600929915956014]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmodel = deepcopy(Primitives.SQRT).add_nodes([\n",
    "    deepcopy(Primitives.SQRT).add_nodes([\n",
    "        deepcopy(Primitives.EXP).add_nodes([\n",
    "            deepcopy(Primitives.TF)\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "print(str(tmodel))\n",
    "learn_population([tmodel], doc_ranks, queries, query_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp(sqrt(log(divide(tf, idf))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13.696360763323469]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmodel = deepcopy(PRIMITIVES[7]).add_nodes([\n",
    "    deepcopy(PRIMITIVES[8]).add_nodes([\n",
    "        deepcopy(PRIMITIVES[6]).add_nodes([\n",
    "            deepcopy(PRIMITIVES[5]).add_nodes([\n",
    "                deepcopy(PRIMITIVES[0]),\n",
    "                deepcopy(PRIMITIVES[1])\n",
    "            ])\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "print(str(tmodel))\n",
    "learn_population([tmodel], doc_ranks, queries, query_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
